# Lane Segmentation with DeepLabV3+

This module performs real-time lane segmentation using DeepLabV3+ with a MobileNetV2 backbone. It is based on TensorFlow 1.x and adapted from the official DeepLab implementation.

## ğŸ“Œ Dataset Disclaimer

The dataset used for training and evaluation is **proprietary to the CSIP Research Lab UOW** and cannot be publicly shared. Only sample directory structure and processing instructions are provided.

## ğŸ“ˆ Performance

- Achieved **95.99% mean Intersection over Union (mIoU)** on the test set  
- Efficient inference using MobileNetV2 and optimized input pipeline  

## ğŸ“ Directory Structure

```
lane_segmentation_deeplabv3/
â”œâ”€â”€ deeplab/     # Core DeepLabV3+ implementation
â”œâ”€â”€ slim/        # TensorFlow slim dependencies
â””â”€â”€ README.md    # This file
```

## ğŸ“š Table of Contents

- [Prerequisites](#prerequisites)  
- [Setup](#setup)  
- [Dataset Preparation](#dataset-preparation)  
- [Data Preprocessing](#data-preprocessing)  
- [Training](#training)  
- [Evaluation](#evaluation)  
- [Inference](#inference)  
- [References](#references)

## ğŸ› ï¸ Prerequisites

Install required Python packages:

```bash
pip install numpy Pillow tf_slim matplotlib
```

## âš™ï¸ Setup

Set `PYTHONPATH` for DeepLab:

```bash
export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
```

## ğŸ—‚ï¸ Dataset Preparation

Organize your dataset as follows:

```
dataset/
â”œâ”€â”€ JPEGImages/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”œâ”€â”€ SegmentationClass/
â”‚   â”œâ”€â”€ image1.png
â”‚   â”œâ”€â”€ image2.png
â””â”€â”€ ImageSets/
    â””â”€â”€ Segmentation/
        â”œâ”€â”€ train.txt
        â”œâ”€â”€ val.txt
        â””â”€â”€ trainval.txt
```

## ğŸ§¼ Data Preprocessing

### 1. ğŸ”„ Convert segmentation masks:

```bash
python deeplab/datasets/remove_gt_colormap.py \
  --original_gt_folder="dataset/SegmentationClass" \
  --output_dir="dataset/SegmentationClassRaw"
```

### 2. ğŸ“¦ Create TFRecord:

```bash
python deeplab/datasets/build_voc2012_data.py \
  --image_folder="dataset/JPEGImages" \
  --semantic_segmentation_folder="dataset/SegmentationClassRaw" \
  --list_folder="dataset/ImageSets/Segmentation" \
  --image_format="jpg" \
  --output_dir="dataset/tfrecord"
```

Update `data_generator.py` to reflect your dataset's number of classes and total samples.

## ğŸ‹ï¸ Training

Download a pre-trained model checkpoint from the [DeepLab Model Zoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md).

Start training:

```bash
python deeplab/train.py \
  --logtostderr \
  --training_number_of_steps=30000 \
  --train_split="train" \
  --model_variant="mobilenet_v2" \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --train_crop_size="513,513" \
  --train_batch_size=1 \
  --dataset="pascal_voc_seg" \
  --tf_initial_checkpoint="pretrained_model/model.ckpt" \
  --train_logdir="training_log" \
  --dataset_dir="dataset/tfrecord"
```

## ğŸ“Š Evaluation

```bash
python deeplab/eval.py \
  --logtostderr \
  --eval_split="val" \
  --model_variant="mobilenet_v2" \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --eval_crop_size="513,513" \
  --dataset="pascal_voc_seg" \
  --checkpoint_dir="training_log" \
  --eval_logdir="eval_log" \
  --dataset_dir="dataset/tfrecord"
```

## ğŸ–¼ï¸ Inference

Visualize predicted segmentation masks:

```bash
python deeplab/vis.py \
  --logtostderr \
  --vis_split="val" \
  --model_variant="mobilenet_v2" \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --vis_crop_size="513,513" \
  --dataset="pascal_voc_seg" \
  --checkpoint_dir="training_log" \
  --vis_logdir="vis_log" \
  --dataset_dir="dataset/tfrecord"
```

## ğŸ“š References

- [DeepLab v3+ Custom Training Guide](https://rockyshikoku.medium.com/train-deeplab-v3-with-your-own-dataset-13f2af958a75)  
- [TensorFlow Models Repository](https://github.com/tensorflow/models)

## Notes

- The training logs and visualization outputs are located under:

```
lane_segmentation_deeplabv3/deeplab/datasets/custom/exp/train_on_trainval_set/
```

- For privacy reasons, only a few example outputs are retained in this repository.
